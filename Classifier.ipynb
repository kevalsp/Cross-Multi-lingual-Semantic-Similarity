{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m------------------Multinomial Naive Bayes-------------------\u001b[0m\n",
      "\n",
      "Acuuracy for english data.\n",
      "82.95454545454545\n",
      "\n",
      "\n",
      "Acuuracy for spanish data\n",
      "75.86206896551724\n",
      "\n",
      "\n",
      "Acuuracy for french data\n",
      "81.03448275862068\n",
      "\n",
      "\u001b[1m--------------Multinomial Logistic Regression---------------\u001b[0m\n",
      "\n",
      "Acuuracy for english data.\n",
      "83.52272727272727\n",
      "\n",
      "\n",
      "Acuuracy for spanish data\n",
      "87.93103448275862\n",
      "\n",
      "\n",
      "Acuuracy for french data\n",
      "87.35632183908046\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk, random\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "vet = CountVectorizer()\n",
    "from sklearn import metrics\n",
    "\n",
    "#--------------------------------------English Data-----------------------------------------------\n",
    "\n",
    "def enf_data():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_eng_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (X)\n",
    "\n",
    "def enf_data1():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_eng_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (Y)\n",
    "a = enf_data()\n",
    "#print(a)\n",
    "\n",
    "b = enf_data1()\n",
    "#print(b)\n",
    "\n",
    "\n",
    "#-------------------------------------Spanish Data----------------------------------------------\n",
    "\n",
    "def spa_data():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_spa_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (X)\n",
    "\n",
    "def spa_data1():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_spa_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (Y)\n",
    "spa_a = spa_data()\n",
    "#print(a)\n",
    "\n",
    "spa_b = spa_data1()\n",
    "#print(b)\n",
    "\n",
    "#---------------------------------French Data---------------------------------------------------------\n",
    "\n",
    "def fra_data():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_fra_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (X)\n",
    "\n",
    "def fra_data1():\n",
    "    path1 = '/Users/kevalpaida/Text Mining Project/Data/CSV/totc_fra_data.csv'\n",
    "    features1 = ['Sentences','Score']\n",
    "    sms1 = pd.read_csv(path1)\n",
    "    #print(sms1)\n",
    "    X = sms1.Sentences\n",
    "    Y = sms1.Score\n",
    "    return (Y)\n",
    "fra_a = fra_data()\n",
    "#print(a)\n",
    "\n",
    "fra_b = fra_data1()\n",
    "#print(b)\n",
    "\n",
    " #==============================Multinomial-NB==================================================\n",
    "\n",
    "\n",
    "\n",
    "def acc (a1,a2):\n",
    "    X = a1\n",
    "    Y = a2\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(Y_train.shape)\n",
    "    #print(Y_test.shape)\n",
    "\n",
    "    vet.fit(X_train)\n",
    "    X_train_dtm = vet.transform(X_train)\n",
    "    #print(X_train_dtm)\n",
    "\n",
    "    #print (\"Test set \\n\")\n",
    "    X_test_dtm = vet.transform(X_test)\n",
    "    #print (X_test_dtm)\n",
    "  \n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, Y_train)\n",
    "\n",
    "    Y_pred_class = nb.predict(X_test_dtm)\n",
    "    #print(Y_pred_class)\n",
    "    from sklearn import metrics\n",
    "    print(metrics.accuracy_score(Y_test, Y_pred_class) * 100)\n",
    "    \n",
    "    \n",
    "start = \"\\033[1m\"\n",
    "end = \"\\033[0m\"\n",
    "\n",
    "\n",
    "print (\"\\n\" + start + \"Multinomial Naive Bayes\".format().center(60,'-') + end +\"\\n\")\n",
    "\n",
    "print(\"Acuuracy for english data.\")\n",
    "eng = acc (a,b) \n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Acuuracy for spanish data\")\n",
    "\n",
    "spa = acc(spa_a,spa_b)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Acuuracy for french data\")\n",
    "\n",
    "fra = acc(fra_a,fra_b)\n",
    "\n",
    "#==============================Multinomial-LR=================================================\n",
    "\n",
    "print (\"\\n\" + start + \"Multinomial Logistic Regression\".format().center(60,'-') + end +\"\\n\")\n",
    "\n",
    "\n",
    "def acc2 (a1,a2):\n",
    "    X = a1\n",
    "    Y = a2\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(Y_train.shape)\n",
    "    #print(Y_test.shape)\n",
    "\n",
    "    vet.fit(X_train)\n",
    "    X_train_dtm = vet.transform(X_train)\n",
    "    #print(X_train_dtm)\n",
    "\n",
    "    #print (\"Test set \\n\")\n",
    "    X_test_dtm = vet.transform(X_test)\n",
    "    #print (X_test_dtm)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    lr.fit(X_train_dtm, Y_train)\n",
    "    Y_pred_class = lr.predict(X_test_dtm)\n",
    "    from sklearn import metrics\n",
    "    print(metrics.accuracy_score(Y_test, Y_pred_class) *100)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Acuuracy for english data.\")\n",
    "eng = acc2 (a,b) \n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Acuuracy for spanish data\")\n",
    "\n",
    "spa = acc2(spa_a,spa_b)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Acuuracy for french data\")\n",
    "\n",
    "fra = acc2 (fra_a,fra_b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
